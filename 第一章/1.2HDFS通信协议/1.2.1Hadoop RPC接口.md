Hadoop RPC调用使得HDFS进程能够像本地调用一样调用另一进城中的方法，并且可以传递JAVA基本类型或者自定义类作为参数，同时接收返回值。如果远程进程在调用过程中出现异常，本地进程也会收到对应异常。
目前Hadoop RPC调用基于Protobuf实现的。

* ClientProtocol : ClientProtocol定义了客户端与NameNode节点之间的接口，这个接口的方法非常多，客户端通过对文件系统的所有操作都需要经过这个接口，同时客户端的读写文件也需要通过这个接口和NameNode协商之后，再进行数据块的读取和写入操作。
* ClientDataNodeProtocol: 客户端与DataNode之间的接口。这个接口主要是用于客户端获取数据节点信息时的调用，而真正的数据读写则通过流式接口进行的。
* DataNodeProtocol: DataNode通过这个接口和NameNode进行通信，同时NameNode节点回通过这个接口中的方法的返回值向DataNode节点下发命令。DataNode会通过这个接口向NameNode注册/汇报数据块的全量及增量的存储情况。DataNode会执行数据块的复制、删除以及恢复操作。
* InterDataNodeProtocol: DataNode和DataNode之间的接口，DataNode通过这个接口和其他的DataNode节点进行通信，这个接口主要应用在数据块的恢复操作，以及同步DataNode节点上存储数据块副本信息。
* NameNodeProtocol: SenconderaryNameNode和NameNode之间的接口。

## ClientProtocol
ClientProtocol定义了所有客户端发起的，由NameNode响应的操作，这个接口包括80多个方法，主要分为：
* HDFS文件读写相关的操作。
* HDFS文件写以及追加的相关操作。
* 管理HDFS命名空间namespace的相关操作。
* 系统问题与管理相关的操作。
* 快照相关的操作。
* 缓存相关的操作。
* 其他


### 读数据相关方法
ClientProtocol中与客户端读取文件相关的方法有两个，getBlockLocations()和reportBadBlocks().   
客户端会调用getBlockLocations() 方法获取HDFS文件指定范围内的所有数据块的位置信息。方法的参数是HDFS的文件名和读取范围，返回值是文件指定范围内的数据块名和它们的位置信息。
当客户端读取数据时候，客户端先调用这个函数来获取文件块的位置信息，然后客户端再从数据节点上读取数据块。
```
public LocatedBlocks getBlockLocations(String src,long offset, long length)
     throws AccessControlException, FileNotFoundException,
     UnresolvedLinkException,IOException
```
客户端会调用和reportBadBlocks() 方法向NameNode汇报错误的数据块。 当客户端从数据节点上读取文件的时候发现数据块的校验并不正确时，就会调用这个方法。
```
public void reportBadBlocks(LocattedBlock[] blocks) throws IOException
```
### 写、追加写数据的方法   
客户端最重要的操作是写一个新文件或者打开一个已有的文件进行追加写操作。 ClientProtocol定义了8中方法支持HDFS的写操作。分别为
create(), append(), addBlock(), complete(), abandonBlock(), getAddtionnalDatanodes(), updateBlockForPipline()和updatePipline()    

create()用在HDFS上面创建一个新的文件，创建路径由src指定，直到这个文件被关闭或者租约到期才能被删除。
客户端在写一个新文件的时候先调用create()函数在文件系统目录上面创建一个空文件，然后调用addBlock()方法获取存储文件的数据块位置信息，最后客户端就可以根据位置信息建立数据流管道。向数据节点写入数据。

客户端追加写一个已有的文件时，会先调用append()方法用于打开一个已有的文件，如果这个文件的最后一个数据块没有写满，则返回这个数据块的位置信息，如果最后一个数据块正好写满，则创建一个新的数据块并添加到这个文件中，然后返回这个新添加的数据块位置信息。

创建新数据块则调用addBlock()方法，向指定文件添加一个新的数据块，并获取存储这个数据块副本的所有数据节点的位置信息，并通过数据流管道写入到数据节点。

当客户端写完成了整个文件的写入操作后，会调用complete（）方法通知NameNOde。 这个操作会提交新写入的HDFS文件的所有数据块，当这些数据块的副本满足系统配置的最小系数，也就是至少有一个副本时，complete会返回true，这时NameNode中文件的状态也会从构建状态转为正常状态，否则complete（）会返回false，客户端就需要重复调用这个操作，直到该方法返回true。

上面的方法是正常情况下，客户端写文件必须要调用的方法。 但对于分布式文件系统，写流程涉及到任何一个节点都有可能发生故障，所以出现故障也需要考虑在内。ClientProtocol定义了abandonBlock(),getAdditionnalDatanode(),updateBlockForPipline和updatePipline（）方法，用于在异常情况下的处理。



